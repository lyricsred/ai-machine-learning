## Classification
Срок сдачи: 20.12.2025 23.59

### Итоги работы
#### Часть 1. Логистическая регрессия своими руками
Реализован алгоритм логистической регрессии с оптимизацией весов методом градиентного спуска 
(классического и стохастического)

Проведен обучение реализованной модели (на обоих методах градиентного спуска) и модели из модуля sklearn. Были получены близкие результаты по метрикам accuracy и ROC-AUC, приведены графики показания функции потерь для итераций градиентного спуска.

Приведены графики разделения на классы после сжатия данных с помощью PCA. Модель, работающая со стохастическим градиентным спуском показывает менее четкую границу между классами по сравнению с двумя другими моделями.

#### Часть 2. Обучение модели на текстовых данных
Для рабочего датасета были заполнены пропуски в данных (пропуски для тестовых признаков пропуски заменялись пустой строкой). Проведена оценка количества уникальных значений для каждого признака.

Выбрана метрика для оценки качества моделей ROC-AUC (менее уязвима к несбалансированности классов), так как объектов нулевого класса в выборке больше.

На первом этапе в выборке оставил только признак 'text' и применил CountVectorizer для увеличения количества признаков. На этих данных обучены модели LogisticRegression и SVC (метод опорных векторов). Модели показали близкий результат на ROC-AUC, но регрессия справилась немного лучше. Кроме того удалось выяснить, что метод опорных векторов занимает больше времени на обучение.

На втором этапе для данных были подобраны гиперпараметры для CountVectorizer, чтобы признаков было в 4 раза меньше, чем объектов в тренировочной выборке. После обучения моделей на новых данных, метрика ROC-AUC для двух моделей упала меньше, чем на 0.01.

На третьем этапе я вернул в тренировочные данные признаки keyword и location и закодировал их с помощью OneHotEncoder. Посчитав метрику ROC-AUC я обнаружил улучшение по сравнению со вторым этапом. Сравнивая с первым этапом, я получил ухудшение для LogisticRegression, но улучшение для SVC.

На четвертом этапе я стал искать подходящие гиперпараметры для моделй через кросс-валидацию (GridSearch). Для логистической регрессии я выбирал коэффициент регуляризации и метод оптимизации функции потерь. Для метода опорных векторов подбирались коэффицент регуляризации, гибкость ядра и функция разделяющей поверхности.

После подбора гиперпараметров метрика ROC-AUC по логистической регрессии оказалась лучше, чем на предыдущем этапе.

Для SVC лучшими гиперпараметрами оказались параметры по умолчанию, поэтому на данном шаге метрика не изменила свое значение.

Построены пайплайны для обоих моделей с предобработкой сырых данных.

Выводы к каждому пункту задания можно найти в ноутбуке.