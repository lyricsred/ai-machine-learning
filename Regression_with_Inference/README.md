## Regression with Inference
Срок сдачи: 
- Первая часть - 01.12.2025 23:59
- Вторая часть - 05.12.2025 23.59

### Результаты работы

#### Часть 1 | EDA и визуализация
Проведены базовый EDA и визуализация.

Удалены полные дубликаты.

Пропуски в данных заполнены средним значением для вещественных признаков, модой для категориальных признаков.

Строковые признаки с указанием единиц измерения переведены в вещественные.

Удалены ненужные признаки.

Выведены основные статистики по всем оставшимся признакам.

В рамках визуализации построены попарные распределения числовых признаков для тренировочной и тестовой выборок.

Построена тепловая карта по данным корреляции между признаками.


#### Часть 2 | Модель только на вещественных признаках
Из выборок выделены только вещественные признаки.

Первой моделью стала классическая линейная регрессия. После обучения на тренировочной выборке и предсказания по тестовым данных, получил MSE = 233691781105.66394 и R^2 = 0.5934582949761261. Метрику MSE интерпретировать труднее в связи с единицами измерения. R^2 отображает достаточно неплохое качество, явно лучше чем предсказание по среднему значению.

Применена стандартизация признаков через StandartScaler. Обучение на новых значениях не привела к улучшению предсказаний на тестовой выборке.

Вторая модель - Lasso регрессия. После обучения она показала метрики MSE = 233692451723.18744 и R^2 = 0.593457128336931, что не сильно превосходить классическую линейную регрессию. При этом модель Lasso не занулила ни один из весов.

Был проведен подбор гиперпараметра alpha для Lasso регрессии через кросс-валидацию на 10 фолдах. Оптимальный гиперпараметр alpha (множитель регуляризаторов) равен 27191.57943036019. При этом удалось достигнуть показателя R^2 = 0.5630804360642326, что является худшим качеством среди упомянутых моделей. MSE = 251153841867.3761.

Третья модель - ElasticNet. Для подбора оптимальных гиперпараметров проведена кросс-валидация на 10 фолдах. Оптимальный гиперпараметр alpha (множитель регуляризаторов) равен 0.49770235643321137, а соотношение между L1 и L2 регуляризаторами l1_ratio = 0.7000000000000001. При этом удалось достигнуть показателя R^2 = 0.5609046367648963, что все еще хуже, чем классическая линейная регрессия. MSE = 252404553435.97275.

#### Часть 3 | Добавляем категориальные признаки

Из выборок удален столбец name, так как не является релевантным для построения модели. Остальные категориальные признаки были закодированы с помощью метода OneHot-кодирования (через pd.get_dummies).

Предпринята попытка обучить модель Ridge. Гиперпараметр alpha (множитель регуляризатора) снова подбирался через кросс-валидацию по 10-ти фолдам. Лучшим значением alpha оказалось 7.09334120498799. при таком значении, значение R^2 на тестовой выборке составило 0.64019144746543, что является лучшим показателем из всех моделей, применонных до этого. MSE = 206828230559.80624.

#### Часть 4 | Бизнесовая

Данная в задаче метрика использовалась как целевая для оценки качества моделей: LinearRegression, Lasso, ElasticNet, Ridge. Несмотря на лучший показатель R^2 у Ridge, для бизнеса более подходящей моделью оказался ElasticNet.

В конечный пайплайн для pickle-файла был внесен StandartScaler, OneHotEncoder и ElasticNet.

#### Часть 5 | Создание интерактивного приложения на Streamlit


Приложение Streamlit позволяет закгрузить csv-файл с данными. Показывает первые 5 строчек. Предлагает на выбор решение задачи классификации или регрессии. Предлагает выбор целевой переменной, удаляет неинформативные признаки.

В блоке визуализации выводит гистограммы распределения признаков, тепловую карту корреляций, диаграммы рассеяния.

На стадии обучения предлагает выбор размера тестовой выборки и значения random_state. при этом показывает метрику R^2 для тестой выборки. Позволяет сделать предсказание на новых данных. Значения для нового объекта можно задать через UI.

Последний блок служит визуализацией коэффициентов модели.

#### Часть 6 | Оформление репозитория и оценка сервиса

Streamlit Community Cloud: https://ml-hometask1-nfqz8prhj8dxbs27m7tu5c.streamlit.app/